import os
import json
import re
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# === âš™ï¸ å…¨å±€é…ç½® (ä¿æŒä¸è®­ç»ƒä¸€è‡´) ===
# ==========================================

# 1. ä¸¥æ ¼å›ºå®šç”»å¸ƒå¤§å° (æµ‹è¯•é›†ä¸“ç”¨)
CANVAS_SIZE = (224, 224) 

# 2. å­—ä½“å¤§å° 
# å»ºè®®ä¸è®­ç»ƒé›†ä¿æŒä¸€è‡´ (ä¾‹å¦‚ 18 æˆ– 20)
FONT_SIZE = 18

# 4. è¾¹è·
MARGIN = 20

# ==========================================

def get_windows_font(size=20):
    """
    Windows ä¸“ç”¨å­—ä½“åŠ è½½å™¨
    ä¼˜å…ˆåŠ è½½å¾®è½¯é›…é»‘ (msyh.ttc) æˆ– é»‘ä½“ (simhei.ttf)
    """
    # Windows å­—ä½“ç›®å½•
    windows_font_dir = r"D:\Downloads\SiYuanHeiTi-Regular\SiYuanHeiTi-Regular"
    
    # ä¼˜å…ˆçº§åˆ—è¡¨
    font_names = [
        "SourceHanSansSC-Regular-2.otf", # æ€æºé»‘ä½“
        "msyh.ttc",   # å¾®è½¯é›…é»‘ (æœ€æ¸…æ™°ï¼Œé¦–é€‰)
        "simhei.ttf", # é»‘ä½“
        "simsun.ttc", # å®‹ä½“
        "arial.ttf"   # è‹±æ–‡ä¿åº•
    ]
    
    for name in font_names:
        font_path = os.path.join(windows_font_dir, name)
        if os.path.exists(font_path):
            try:
                return ImageFont.truetype(font_path, size)
            except Exception as e:
                continue
    
    print("âš ï¸ æœªæ‰¾åˆ°å¸¸ç”¨ä¸­æ–‡å­—ä½“ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å­—ä½“...")
    return ImageFont.load_default()

def render_text_to_fixed_384(text, save_path):
    """
    ã€æµ‹è¯•é›†ä¸“ç”¨ã€‘å›ºå®š 384x384 ç”»å¸ƒçš„æ™ºèƒ½æ¸²æŸ“å‡½æ•°
    1. ç”»å¸ƒå¤§å°é”æ­»ä¸º 384x384ã€‚
    2. æ™ºèƒ½æ’ç‰ˆï¼Œä¸åˆ‡æ–­å•è¯ã€‚
    3. å¦‚æœæ–‡å­—å¤ªé•¿ï¼Œè¶…å‡º 384 é«˜åº¦ï¼Œåˆ™ç›´æ¥æˆªæ–­ï¼ˆä¸å†ç»˜åˆ¶ï¼‰ã€‚
    """
    # 1. å‡†å¤‡ç”»å¸ƒ
    img = Image.new('RGB', CANVAS_SIZE, (255, 255, 255)) # ç™½åº•
    draw = ImageDraw.Draw(img)
    font = get_windows_font(FONT_SIZE)
    
    # 2. è®¡ç®—æ’ç‰ˆå‚æ•°
    max_text_width = CANVAS_SIZE[0] - 2 * MARGIN
    max_text_height = CANVAS_SIZE[1] - MARGIN # ç•™å‡ºä¸‹è¾¹è·
    
    line_height = int(FONT_SIZE * 1.5)
    
    current_y = MARGIN
    current_line = ""
    
    # 3. æ–‡æœ¬åˆ†æ®µä¸åŸå­åŒ–
    paragraphs = text.split('\n')
    
    stop_rendering = False # æ ‡å¿—ä½ï¼šå¦‚æœç”»å¸ƒæ»¡äº†å°±åœæ­¢
    
    for para in paragraphs:
        if stop_rendering: break
        
        # æ­£åˆ™åˆ‡åˆ†åŸå­ (ä¸­æ–‡å­—ç¬¦ / è‹±æ–‡å•è¯ / ç©ºæ ¼)
        atoms = re.findall(r'[\u4e00-\u9fa5]|[^\u4e00-\u9fa5\s]+|\s+', para)
        
        for atom in atoms:
            test_line = current_line + atom
            
            # è®¡ç®—å®½åº¦
            if hasattr(font, 'getlength'):
                width = font.getlength(test_line)
            else:
                width = draw.textlength(test_line, font=font)
            
            if width <= max_text_width:
                current_line = test_line
            else:
                # --- ç»˜åˆ¶å½“å‰è¡Œ ---
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé«˜åº¦
                if current_y + line_height > max_text_height:
                    stop_rendering = True
                    break
                
                if current_line:
                    draw.text((MARGIN, current_y), current_line, font=font, fill=(0, 0, 0))
                    current_y += line_height
                
                # --- å¤„ç†æ–°çš„ä¸€è¡Œ ---
                atom_width = font.getlength(atom) if hasattr(font, 'getlength') else draw.textlength(atom, font=font)
                if atom_width > max_text_width:
                    current_line = atom # å¼ºåˆ¶æ¢è¡Œ
                else:
                    current_line = atom.lstrip() # æ–°èµ·ä¸€è¡Œ
        
        # æ®µè½ç»“æŸï¼Œç»˜åˆ¶ç¼“å†²åŒºå‰©ä½™å†…å®¹
        if not stop_rendering and current_line:
            if current_y + line_height > max_text_height:
                stop_rendering = True
            else:
                draw.text((MARGIN, current_y), current_line, font=font, fill=(0, 0, 0))
                current_y += line_height
                current_line = "" # æ¸…ç©ºï¼Œå‡†å¤‡ä¸‹ä¸€æ®µ
                
        # (å¯é€‰) æ®µè½é—´ç©ºè¡Œé€»è¾‘ï¼Œå¦‚æœä¸éœ€è¦ç´§å‡‘æ’ç‰ˆå¯ä»¥å¼€å¯
        # if not stop_rendering:
        #     current_y += int(line_height * 0.5) 

    # 4. ä¿å­˜
    img.save(save_path)


# ==========================================
# === æ‰¹é‡å¤„ç†å…¥å£ (é’ˆå¯¹æµ‹è¯•é›†) ===
# ==========================================

def process_test_dataset(json_path, output_base_dir):
    """å¤„ç†æµ‹è¯•é›†æ•°æ® (NLPCC æˆ–å…¶ä»– JSON æ ¼å¼)"""
    
    human_dir = os.path.join(output_base_dir, "human")
    ai_dir = os.path.join(output_base_dir, "ai")
    
    os.makedirs(human_dir, exist_ok=True)
    os.makedirs(ai_dir, exist_ok=True)
    
    if not os.path.exists(json_path):
        print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        return
    
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå›ºå®šæµ‹è¯•é›† (384x384): {json_path}")
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data_list = json.load(f)
    
    count = 0
    for item_id, item in enumerate(data_list, start=1):
        try:
            text = item.get('text', '').strip()
            label = item.get('label', -1)
            item_id_val = item.get('id', item_id)
            
            if not text: continue
            
            # åªæœ‰è¿™é‡Œä¸åŒï¼šè°ƒç”¨ render_text_to_fixed_384
            if label == 0: # human
                output_path = os.path.join(human_dir, f"{item_id_val}.png")
                render_text_to_fixed_384(text, output_path) 
                count += 1
            elif label == 1: # ai
                output_path = os.path.join(ai_dir, f"{item_id_val}.png")
                render_text_to_fixed_384(text, output_path) 
                count += 1
                
            if count % 100 == 0:
                print(f"å·²ç”Ÿæˆ {count} å¼ ...", end='\r')
                
        except Exception as e:
            print(f"Error ID {item_id_val}: {e}")

    print(f"\nğŸ‰ æµ‹è¯•é›†ç”Ÿæˆå®Œæˆ! å…± {count} å¼ ã€‚")

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šç”Ÿæˆ DetectRL-zh çš„æµ‹è¯•é›†
    test_json_file = r"d:\Desktop\æ–‡æœ¬æ£€æµ‹\NLPCC-2025-Task1-main\data\test_with_label.json" 
    test_output_dir = r"/dataset/detectRL-zh/384/test"
    
    process_test_dataset(test_json_file, test_output_dir)